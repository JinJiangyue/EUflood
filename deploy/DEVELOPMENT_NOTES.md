# Development Notes

## 1.0.4 - 2025-11-07（新增条目，旧内容保留在本条目下方）

### LLM 驱动处理架构

**设计理念**：
- 完全使用 LLM 替代规则驱动的处理逻辑
- 4 步处理流程：验证→提取→筛选→生成
- 支持 OpenAI 和 Google Gemini 两种 LLM 提供商，可配置切换

**LLM 客户端抽象**：
- 创建 `LLMClient` 抽象基类，统一接口
- `OpenAIClient` 和 `GeminiClient` 实现具体逻辑
- 工厂函数 `create_llm_client` 根据配置创建对应客户端
- 统一的 JSON 解析逻辑，处理各种格式问题（代码块、截断等）

**Prompt 设计原则**：
- 明确 JSON 格式要求，避免 LLM 生成非 JSON 内容
- 限制输入长度：缩短摘要、移除不必要字段
- 明确禁止虚构内容：要求 LLM 只使用真实数据
- 可配置的时间窗口：通过参数传递，而非硬编码

**成本优化策略**：
- 预过滤机制：在交给 LLM 前进行规则判断，减少输入 token
- 智能跳过：无搜索结果或验证无相关结果时跳过后续步骤
- 可配置限制：`MAX_ITEMS_FOR_LLM_VALIDATION` 控制输入数量
- Token 使用监控：记录每次调用的 token 使用情况

### 预过滤机制设计

**目的**：在交给 LLM 前进行简单规则判断，减少 token 消耗和提高准确性

**检查项**：
1. **时间匹配**：
   - 优先使用 `published_at` 字段
   - 如果为空，从 URL 中提取日期（格式：`/2025/10/27/` 或 `/2025-10-27/`）
   - 如果 URL 也没有，从标题和摘要中提取日期（格式：`October 29, 2025` 或 `10/29/2025`）
   - 只保留事件时间 + N 天内的结果（不包括事件之前的内容）
2. **地点匹配**：标题或摘要包含省名或国家名
3. **关键词匹配**：标题或摘要包含 rain/flood 等关键词

**模式选择**：
- `strict`：必须同时满足时间+地点+关键词（推荐，减少 token 消耗）
- `loose`：满足任意一个即可（保留更多结果，可能包含不相关项）

**实现细节**：
- 使用正则表达式从 URL 和文本中提取日期
- 支持多种日期格式（ISO、自然语言、数字格式）
- 详细的过滤日志，记录每个被过滤项的原因

### 关键词生成优化

**地点策略**：
- 省级优先：忽略具体雨量站城市，使用省级名称
- 国家组合：使用 "省 国家" 的组合（如 "Valencia España"）
- 本地化国家名：非英语语言使用本地国家名（如西班牙语使用 "España"）

**时间处理**：
- 自然语言格式：将事件时间转换为自然语言（如 "October 11, 2025" 或 "11 octubre 2025"）
- 查询字符串：时间包含在查询字符串中
- API 参数：同时作为 API 的时间过滤参数

**去重逻辑**：
- 避免重复关键词（如 "Valencia Valencia España"）
- 智能选择：优先使用 "省 国家" 组合，如果没有则使用单独的省名
- 灾害术语去重：确保每个术语只出现一次

### 多语言搜索策略

**语言识别**：
- 使用 `terminology.json` 存储国家与官方语言映射
- `GeoLinguaResolver` 根据地点识别国家和官方语言
- 支持多语言术语（rain/flood 的本地翻译）

**搜索策略**：
- 使用本地语言进行搜索（如西班牙语、挪威语）
- 查询字符串使用本地语言关键词
- API 参数使用对应的语言代码

**术语处理**：
- 从 `terminology.json` 获取本地术语
- 处理 `None` 值：使用 `profile.get("term") or "default"` 避免 None 值

### 详细日志系统

**设计目的**：提供完整的处理过程透明度，便于调试和审计

**日志内容**：
- 输入数据：事件信息
- 搜索请求：每个采集器的请求参数
- 搜索响应：解析后的结果
- LLM 请求：Prompt 内容、配置参数
- LLM 响应：原始响应、解析后的结果
- 预过滤详情：被过滤项的原因和检查结果

**输出格式**：
- Markdown 格式，便于阅读
- 按步骤组织，清晰展示数据流
- 保存到 `test_log.md` 文件

### 中间结果保存

**目的**：提供处理过程的可见性，便于调试和验证

**保存的文件**：
1. `{event_id}_raw_items_before_filter.md`：预过滤前的原始搜索结果
2. `{event_id}_filtered_items_after_prefilter.md`：预过滤后的结果（标注哪些会交给 LLM）
3. `{event_id}_llm_validation_results.md`：LLM 验证结果（包括相关项和不相关项的排除原因）

**内容格式**：
- Markdown 格式
- 包含事件信息、统计信息、详细结果列表
- 便于人工审查和验证

### 错误处理最佳实践

**LLM 响应解析**：
- 处理代码块标记（```json 或 ```）
- 处理截断的 JSON（尝试补全缺失的括号）
- 处理各种格式问题（引号、转义字符等）
- 详细的错误日志，记录所有尝试的方法

**API 调用**：
- 完善的错误处理和重试机制
- 详细的错误日志
- 优雅降级：API 失败时返回空结果，不中断流程

**数据验证**：
- 输入数据验证（事件信息、配置参数）
- 输出数据验证（LLM 响应格式）
- 默认值处理：缺失数据使用合理的默认值

### 配置管理

**统一配置**：
- 所有配置项集中在 `settings.py`
- 使用 `pydantic-settings` 从 `.env` 文件加载
- 统一的 `.env` 文件在项目根目录

**配置项分类**：
- 基础运行参数（环境、日志级别）
- 数据库配置（连接、表名、列名）
- 搜索配置（时间窗口、预过滤）
- LLM 配置（提供商、模型、参数）
- API 密钥配置

**默认值策略**：
- 所有配置项都有合理的默认值
- 关键配置项在 `env.template` 中有详细说明
- 配置验证：使用 pydantic 进行类型和值验证

### 代码清理经验

**识别废弃代码**：
- 检查导入和使用情况
- 确认功能是否已被替代
- 保留备选代码（如 gnews、serpapi）但注释掉导入

**文档清理**：
- 删除调试和研究过程中产生的临时文档
- 保留有用的文档（README、INSTALL、TEST、CONFIGURATION_GUIDE）
- 统一文档格式和结构

**目录清理**：
- 删除废弃的目录（processing、reporting）
- 清理误创建的目录
- 保持目录结构清晰

## 1.0.2 - 2025-01-13（新增条目，旧内容保留在本条目下方）

### 空间插值分析增强经验

**行政区解析策略**：
- 采用"先域 GeoJSON，后 LAU"的顺序：先用域 GeoJSON 做空间筛选并解析国家/省，再用 LAU 补充城市
- 域 GeoJSON 字段优先级：CNTR_CODE → country_code，NUTS_NAME → province_name，NAME 作为兼容（如 ES_Murcia）
- LAU 仅取 LAU_NAME → city_name，不覆盖已解析的国家/省

**sjoin 列名后缀问题**：
- GeoPandas 的 sjoin 在左右表有同名列时会自动加后缀（_right/_left）
- 解决方案：代码中同时查找 ['NAME', 'NAME_right', 'NAME_left'] 等变体
- 关键发现：域 GeoJSON 的 NAME 在 sjoin 后可能变成 NAME_right，必须兼容

**数据流设计**：
- 第一阶段：域 GeoJSON 空间筛选 → 解析国家/省（保留在 final_points）
- 第二阶段：LAU sjoin → 仅补充 city_name，不触碰国家/省
- 避免覆盖：删除 NUTS 省级 sjoin 分支，防止覆盖已解析的 province_name

**阈值可配置化**：
- 前端输入框改为可编辑（去掉 readonly）
- 后端默认值 50.0，前端传值则覆盖
- 验证逻辑：非法值回退到 50.0

**代码精简原则**：
- 删除所有"尝试多种字段"的冗余逻辑，只保留实际使用的字段
- 移除不必要的日志和调试代码
- 保持表结构干净：只存必需字段，不存文件名/版本等元数据

**测试脚本增强**：
- 使用子进程方式运行，捕获 stdout/stderr 分别处理
- 高亮显示关键日志（域 GeoJSON 字段解析）
- 统计缺失省名的点，便于快速定位问题

## 1.0.1 - 2025-01-13（新增条目，旧内容保留在本条目下方）

### 前端重构经验

**模块化拆分策略**：
- 将 1694 行的单文件拆分为多个模块，每个模块职责清晰
- 按功能划分：stats（统计）、search（搜索）、events（事件）、map（地图）、interpolation（插值）、data-management（数据管理）
- 工具函数独立：`utils.js` 包含可复用的通用函数

**目录结构设计**：
- `frontend/css/`：样式文件（main.css 主样式，map.css 地图样式）
- `frontend/js/modules/`：功能模块
- `frontend/js/utils.js`：工具函数
- `frontend/js/main.js`：主入口，初始化所有模块

**全局变量管理**：
- 地图相关变量（`map`, `geojsonLayer`, `dataPointsLayer` 等）通过 `window` 对象暴露
- 确保模块间可以共享状态
- 保持向后兼容，不影响现有功能

**静态文件服务配置**：
- Express 使用 `express.static` 中间件提供 `frontend/` 目录
- 正确设置 MIME 类型：CSS 为 `text/css`，JS 为 `application/javascript`
- 路径解析：使用 `path.resolve(__dirname, '../../..')` 获取项目根目录

**模块加载顺序**：
- 工具函数 → 功能模块 → 主入口
- 在 HTML 中按依赖关系顺序引用
- 使用 `typeof` 检查函数是否存在，避免未定义错误

**重构优势**：
- 可维护性：代码结构清晰，易于定位和修改
- 可扩展性：新增功能只需添加新模块，不影响现有代码
- 可测试性：模块可独立测试
- 性能：按需加载，减少初始加载体积
- 零构建：无需构建工具，开发简单

### Python 模块集成经验

**嵌入式 Python 策略**：
- 使用嵌入式 Python 3.12，避免系统 Python 版本冲突
- 路径解析采用多级回退机制：环境变量 → 相对路径 → 绝对路径 → 系统 Python
- 通过 `apps/api/.env` 配置 `PYTHON_PATH` 可灵活指定 Python 路径

**坐标转换优化**：
- 初始使用 `apply()` 逐行转换，性能差（19700 个点需要数分钟）
- 改为批量转换（列表推导式），性能提升 100+ 倍
- 使用 `pyproj.Transformer` 一次性转换所有坐标，避免重复创建 transformer

**文件读取灵活性**：
- 支持无表头文件（自动检测：如果第一行全是数字，视为无表头）
- 支持多种分隔符：制表符、逗号、空格、分号
- 优先使用制表符分隔（与原始数据格式一致）
- 自动列名检测：支持常见经纬度列名（longitude/lon/lng/x, latitude/lat/y）

**GeoJSON 空间筛选**：
- 使用 `geopandas.sjoin` 进行空间连接（within 谓词）
- 坐标系统统一：确保 GeoJSON 和点数据都使用 EPSG:4326
- 每区域最大值：使用 `drop_duplicates(subset='index_right', keep='first')` 实现

**前端地图集成**：
- Leaflet.js 初始化问题：需要确保容器可见（`display: block`）再初始化
- 防止重复初始化：检查 `_leaflet_id` 属性
- 错误处理：区分网络错误、超时错误、文件错误，提供针对性建议
- 超时设置：前端 5 分钟，后端 4 分钟（留缓冲时间）

**错误处理最佳实践**：
- Python 脚本：所有进度信息输出到 `stderr`，结果输出到 `stdout`
- Node.js 执行器：捕获 `stderr` 中的 JSON 错误信息，解析并返回
- 前端：区分不同类型的错误（网络、超时、文件、处理），提供具体解决建议
- 日志：在关键步骤添加 `[Progress]` 标记，便于调试

**测试策略**：
- 提供独立的测试脚本 `test_interpolation.py`，可直接运行，无需通过网页
- 测试脚本自动创建示例数据文件（如果不存在）
- 支持命令行参数和配置文件两种方式
- 批处理脚本 `run_test.bat` 方便 Windows 用户快速测试

**性能优化经验**：
- 大数据量处理：19700 个点 → 阈值筛选 25 个 → GeoJSON 筛选 20 个 → 每区域最大值 8 个
- 批量操作优于逐行操作：坐标转换、数据筛选都使用批量方式
- 内存管理：及时关闭图形对象（matplotlib），避免内存泄漏

**数据格式兼容性**：
- 支持多种输入格式：有表头/无表头、多种分隔符、不同坐标系统
- 自动检测和处理：坐标系统、列名、分隔符
- 向后兼容：即使格式不完全匹配，也能尽量解析

## 1.0.0 - 2025-11-05（新增条目，旧内容保留在本条目下方）
- 后端 TS、前端原生 JS：后端有编译链路利于可维护性；前端为零构建即用。
- SQLite 开发策略：用 better-sqlite3（同步、稳定）；通过 PRAGMA 检测列并在线升级，兼容旧库。
- 多源采集：将不同来源差异抽象为记录生成器；统一字段后用 `record_id` 去重，合并证据数与置信度。
- 置信度模型：源头权重 + 字段完整度 + 多源一致度（上限 0.95）；合并时取更高值。
- 地理编码：先内置映射模拟；后续可替换为 Nominatim/Google Geocoding。
- 搜索：从拼关键词改为结构化参数（country/date/severity），q 仍可选。
- 首页直连 API：避免前后端耦合复杂度，先保障可视化验证。
- 迁移策略：将 Postgres 迁移 SQL 留在 `apps/api/sql/migrations` 供未来迁移参考。


